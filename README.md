# NFL Data Platform

**Independent functional modules** for NFL data processing. Each module is self-contained and can be developed, tested, and deployed separately.

---

## ğŸ§ª Testing

Install the lightweight dev dependencies and run the shared pytest suite from the project root:

```bash
python -m pip install -r requirements-dev.txt
pytest
```

Each module-specific test lives under `tests/<module_name>/` to respect function isolation. You can target a single module (for example, `pytest tests/story_embeddings`) when working locally.

## ğŸ“¦ Functional Modules

### Data Loading
NFL data ingestion, transformation, and on-demand package assembly.

- **Location**: [`src/functions/data_loading/`](src/functions/data_loading/)
- **Status**: âœ… Production Ready
- **Features**: Warehouse datasets, on-demand packages, Cloud Function API, CLI tools, weekly injury reports (see README for schema/testing details)

[**â†’ Full Documentation**](src/functions/data_loading/README.md)

**Quick Start:**
```bash
cd src/functions/data_loading
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env  # Configure Supabase

# Load data
python scripts/players_cli.py --dry-run
python scripts/games_cli.py --season 2024

# Load injury reports (see README "Injuries Loader")
python scripts/injuries_cli.py --season 2025 --week 6

# Test locally
cd functions && ./run_local.sh

# Deploy
./deploy.sh
```

### News Extraction
NFL news URL extraction from RSS feeds and sitemaps.

- **Location**: [`src/functions/news_extraction/`](src/functions/news_extraction/)
- **Status**: âœ… Production Ready
- **Features**: Concurrent extraction, HTTP caching, circuit breaker, comprehensive monitoring

[**â†’ Full Documentation (testing & deployment included)**](src/functions/news_extraction/README.md)

**Quick Start:**
```bash
cd src/functions/news_extraction
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env  # Configure Supabase

# Extract news
python scripts/extract_news_cli.py --dry-run --verbose

# Production with metrics
python scripts/extract_news_cli.py --environment prod --metrics-file metrics.json

# Deploy (see README testing & deployment notes)
cd functions && ./deploy.sh
```

### Content Summarization
AI-powered content summarization using Google Gemini with intelligent fallback strategies.

- **Location**: [`src/functions/content_summarization/`](src/functions/content_summarization/)
- **Status**: âœ… Production Ready
- **Features**: Fact-first pipeline (facts â†’ embeddings â†’ summaries), Supabase edge queue integration, backlog processor with concurrency/heartbeats, rate limiting, circuit breaker, rich metrics

[**â†’ Full Documentation**](src/functions/content_summarization/README.md)

**Quick Start:**
```bash
cd src/functions/content_summarization
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# Add to .env: GEMINI_API_KEY (plus optional overrides in README)

# Run factâ†’summary pipeline
python scripts/content_pipeline_cli.py --stage full --limit 20

# High-volume backlog run (see README for more flags)
python scripts/backlog_processor.py --stage facts --limit 1000 --prefetch-size 1000

# Deploy
cd functions && ./deploy.sh
```

### Story Embeddings
Vector embeddings for NFL news story summaries using OpenAI's text-embedding-3-small model.

- **Location**: [`src/functions/story_embeddings/`](src/functions/story_embeddings/)
- **Status**: âœ… Production Ready
- **Features**: Smart processing (LEFT JOIN for new summaries), timeout handling, rate limiting, error recovery, batch operations, cost tracking

[**â†’ Full Documentation**](src/functions/story_embeddings/README.md)

**Quick Start:**
```bash
cd src/functions/story_embeddings
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# Add to .env: OPENAI_API_KEY

# Check progress
python scripts/generate_embeddings_cli.py --progress

# Test (no changes)
python scripts/generate_embeddings_cli.py --dry-run --limit 5

# Generate embeddings
python scripts/generate_embeddings_cli.py --limit 50 --verbose
```

### Story Grouping
Clusters similar NFL news stories based on embedding vectors using cosine similarity and centroid-based clustering.

- **Location**: [`src/functions/story_grouping/`](src/functions/story_grouping/)
- **Status**: âœ… Production Ready
- **Features**: Cosine similarity clustering, dynamic centroids, batch processing with pagination, dry-run mode, progress tracking

[**â†’ Full Documentation**](src/functions/story_grouping/README.md)

**Quick Start:**
```bash
cd src/functions/story_grouping
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# Add to .env: SUPABASE_URL, SUPABASE_KEY, SIMILARITY_THRESHOLD

# Check progress
python scripts/group_stories_cli.py --progress

# Test (no changes)
python scripts/group_stories_cli.py --dry-run --limit 10

# Group stories
python scripts/group_stories_cli.py
```

### Knowledge Extraction
Extracts key topics and NFL entities from story groups using GPT-5-mini reasoning model with fuzzy entity matching.

- **Location**: [`src/functions/knowledge_extraction/`](src/functions/knowledge_extraction/)
- **Status**: âœ… Production Ready
- **Features**: GPT-5-mini with medium reasoning, fuzzy entity matching, retry logic, circuit breakers, batch processing, dry-run mode

[**â†’ Full Documentation**](src/functions/knowledge_extraction/README.md)

**Quick Start:**
```bash
cd src/functions/knowledge_extraction
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# Add to .env: OPENAI_API_KEY

# Run schema.sql in Supabase SQL Editor

# Check progress
python scripts/extract_knowledge_cli.py --progress

# Test (no changes)
python scripts/extract_knowledge_cli.py --dry-run --limit 5

# Extract knowledge
python scripts/extract_knowledge_cli.py
```

---

## ğŸ¤– Automated Content Pipeline

Fully automated GitHub Actions run every 30 minutes to move articles from raw URLs â†’ content â†’ facts â†’ knowledge â†’ summaries. The pipeline now runs as two coordinated workflows with strict gating and batch tracking to avoid duplicates.

### What Runs Where

- **content-pipeline-create.yml** (creator): Extracts URLs â†’ fetches article content (Playwright) â†’ submits OpenAI **facts** batch. Skips work when there are no new URLs unless `force_content_fetch` is set.
- **content-pipeline-poll.yml** (processor): Polls OpenAI batches, writes results, and promotes to the next stage using the `batch_jobs` tracking table to prevent overlap. Promotions require a minimum processed count (default `MIN_PROMOTION_ITEMS=100`):
  - Facts â†’ Knowledge (topics)
  - Knowledge (topics) â†’ Knowledge (entities)
  - Knowledge (entities) â†’ Summaries

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUTOMATED CONTENT PIPELINE                               â”‚
â”‚                    Runs every 30 minutes (cron)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  WORKFLOW 1: content-pipeline-create.yml ("creator")                â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  â€¢ Extract news URLs (days_back=1) â†’ writes new URL IDs artifact    â”‚   â”‚
â”‚  â”‚  â€¢ Fetch article content with Playwright (10 workers, 45s timeout)  â”‚   â”‚
â”‚  â”‚    - Skips if no new URLs unless force_content_fetch=true           â”‚   â”‚
â”‚  â”‚  â€¢ Create facts batch (limit configurable, default 500)             â”‚   â”‚
â”‚  â”‚    - only validated articles, max age 48h, registers in Supabase    â”‚   â”‚
â”‚  â”‚    - OpenAI Batch API: async, ~24h, 50% cheaper                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚                              â¬‡ï¸  Facts batch queued with OpenAI             â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  WORKFLOW 2: content-pipeline-poll.yml ("processor")                â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  â€¢ Polls batch_jobs table for pending batches and OpenAI status     â”‚   â”‚
â”‚  â”‚  â€¢ Processes completed batches and writes to Supabase               â”‚   â”‚
â”‚  â”‚  â€¢ Promotions (threshold-controlled):                               â”‚   â”‚
â”‚  â”‚      Facts â†’ Knowledge (topics)                                     â”‚   â”‚
â”‚  â”‚      Topics â†’ Knowledge (entities)                                  â”‚   â”‚
â”‚  â”‚      Entities â†’ Summaries (with embeddings)                         â”‚   â”‚
â”‚  â”‚  â€¢ Retries processing failures; skips OpenAI-failed batches         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline Stages Explained

| Stage | What It Does | How Long |
|-------|--------------|----------|
| **1. News Extraction** | Scans RSS/sitemaps for new NFL URLs; writes ID list artifact | ~30 seconds |
| **2. Content Fetching** | Fetches article HTML with Playwright (skips if no new URLs unless forced) | ~2â€“5 minutes |
| **3. Facts Extraction** | Submits OpenAI Batch API job for validated content (max age 48h, max 25 facts per URL) | Up to 24h* |
| **4. Knowledge (Topics â†’ Entities)** | Sequential batches over facts; topics must meet threshold before entities | Up to 24h* each |
| **5. Summary Generation** | Generates summaries + embeddings from facts; promotes only when prior stage meets threshold | Up to 24h* |

*Batch API is ~50% cheaper; most complete sooner.

### Key Features

- **ğŸ”„ Cron + Concurrency Guards**: Both workflows scheduled every 30 minutes with non-canceling concurrency groups
- **ğŸ¯ Gated Promotions**: Next stage created only after thresholds (default `MIN_PROMOTION_ITEMS=100`)
- **ğŸ“¦ Batch Tracking**: `batch_jobs` table records stage, status, retry count, and OpenAI file IDs
- **ğŸ’° Batch API**: Uses OpenAI Batch for cost and queueing benefits
- **ğŸ” Safe Retries**: Retries processing failures; OpenAI-failed batches are left for manual re-creation
- **âš¡ Smart Skips**: Content fetch and batch creation skip when no new work; `force_content_fetch` overrides

### Workflow Files

| File | Purpose |
|------|---------|
| [`.github/workflows/content-pipeline-create.yml`](.github/workflows/content-pipeline-create.yml) | Creates new batches (extract news â†’ fetch content â†’ create facts batch) |
| [`.github/workflows/content-pipeline-poll.yml`](.github/workflows/content-pipeline-poll.yml) | Polls and processes completed batches, creates next-stage batches |

### Required Secrets

Configure these in your GitHub repository settings (Settings â†’ Secrets â†’ Actions):

| Secret | Description |
|--------|-------------|
| `SUPABASE_URL` | Your Supabase project URL |
| `SUPABASE_KEY` | Your Supabase service role key |
| `OPENAI_API_KEY` | OpenAI API key for Batch API access |

### Manual Triggers

You can manually trigger either workflow from GitHub Actions:

```
GitHub â†’ Actions â†’ Content Pipeline - Create Batches â†’ Run workflow
```

Optional inputs for manual runs:
- **Skip news extraction**: Jump straight to content fetching
- **Skip content fetch**: Only create facts batch
- **Force content fetch**: Run content fetch even when no new URLs were just inserted
- **Facts limit**: Control facts batch size (default: 20)
- **Poll: force check all**: Processor will re-check all pending batches

### Monitoring

Check workflow status in GitHub Actions. Each run shows:
- âœ… Steps completed successfully
- âŒ Steps that failed (with logs)
- â„¹ï¸ Informational messages (e.g., "No new articles to process")

---

## ğŸ—ï¸ Architecture

**Function-Based Isolation** - Each module operates independently:

```
T4L_data_loaders/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ shared/                    # Minimal shared utilities
â”‚   â”‚   â”œâ”€â”€ utils/                 # Logging, environment loading
â”‚   â”‚   â””â”€â”€ db/                    # Generic database helpers
â”‚   â”‚
â”‚   â””â”€â”€ functions/                 # Independent functional modules
â”‚       â”œâ”€â”€ data_loading/          # âœ… Production ready
â”‚       â”‚   â”œâ”€â”€ core/              # Business logic (60+ files)
â”‚       â”‚   â”œâ”€â”€ scripts/           # CLI tools (8 scripts)
â”‚       â”‚   â”œâ”€â”€ functions/         # Cloud Function deployment
â”‚       â”‚   â”œâ”€â”€ requirements.txt   # Module dependencies
â”‚       â”‚   â””â”€â”€ README.md          # Module documentation
â”‚       â”‚
â”‚       â”œâ”€â”€ news_extraction/       # âœ… Production ready
â”‚       â”‚   â”œâ”€â”€ core/              # Business logic
â”‚       â”‚   â”‚   â”œâ”€â”€ config/        # YAML configuration
â”‚       â”‚   â”‚   â”œâ”€â”€ extractors/    # RSS/sitemap extractors
â”‚       â”‚   â”‚   â”œâ”€â”€ pipelines/     # Orchestration
â”‚       â”‚   â”‚   â”œâ”€â”€ processors/    # URL filtering
â”‚       â”‚   â”‚   â”œâ”€â”€ data/          # Transformers
â”‚       â”‚   â”‚   â”œâ”€â”€ db/            # Database writer
â”‚       â”‚   â”‚   â””â”€â”€ monitoring.py  # Metrics & logging
â”‚       â”‚   â”œâ”€â”€ scripts/           # CLI tools
â”‚       â”‚   â”œâ”€â”€ functions/         # Cloud Function deployment
â”‚       â”‚   â”œâ”€â”€ requirements.txt   # Module dependencies
â”‚       â”‚   â””â”€â”€ README.md          # Module documentation
â”‚       â”‚
â”‚       â”œâ”€â”€ content_summarization/ # âœ… Production ready
â”‚       â”‚   â”œâ”€â”€ core/              # Business logic
â”‚       â”‚   â”‚   â”œâ”€â”€ contracts/     # Data models
â”‚       â”‚   â”‚   â”œâ”€â”€ db/            # Database operations (pagination, retry)
â”‚       â”‚   â”‚   â”œâ”€â”€ llm/           # Gemini client + fallback fetcher
â”‚       â”‚   â”‚   â””â”€â”€ pipelines/     # Orchestration
â”‚       â”‚   â”œâ”€â”€ scripts/           # CLI tools
â”‚       â”‚   â”œâ”€â”€ functions/         # Cloud Function deployment
â”‚       â”‚   â”œâ”€â”€ requirements.txt   # Module dependencies
â”‚       â”‚   â””â”€â”€ README.md          # Module documentation
â”‚       â”‚
â”‚       â”œâ”€â”€ story_embeddings/      # âœ… Production ready
â”‚           â”œâ”€â”€ core/              # Business logic
â”‚           â”‚   â”œâ”€â”€ contracts/     # Data models (SummaryRecord, StoryEmbedding)
â”‚           â”‚   â”œâ”€â”€ db/            # Database operations (reader, writer)
â”‚           â”‚   â”œâ”€â”€ llm/           # OpenAI client with production features
â”‚           â”‚   â””â”€â”€ pipelines/     # Orchestration pipeline
â”‚           â”œâ”€â”€ scripts/           # CLI tools
â”‚           â”œâ”€â”€ requirements.txt   # Module dependencies
â”‚           â”œâ”€â”€ schema.sql         # Database schema
â”‚           â””â”€â”€ README.md          # Module documentation
â”‚       â”‚
â”‚       â”œâ”€â”€ story_grouping/        # âœ… Production ready
â”‚       â”‚   â”œâ”€â”€ core/              # Business logic
â”‚       â”‚   â”‚   â”œâ”€â”€ clustering/    # Similarity algorithms, grouping logic
â”‚       â”‚   â”‚   â”œâ”€â”€ db/            # Database operations (with pagination)
â”‚       â”‚   â”‚   â””â”€â”€ pipelines/     # Orchestration pipeline
â”‚       â”‚   â”œâ”€â”€ scripts/           # CLI tools
â”‚       â”‚   â”œâ”€â”€ functions/         # Cloud Function deployment (future)
â”‚       â”‚   â”œâ”€â”€ requirements.txt   # Module dependencies
â”‚       â”‚   â”œâ”€â”€ schema.sql         # Database schema
â”‚       â”‚   â””â”€â”€ README.md          # Module documentation
â”‚       â”‚
â”‚       â””â”€â”€ knowledge_extraction/  # âœ… Production ready
â”‚           â”œâ”€â”€ core/              # Business logic
â”‚           â”‚   â”œâ”€â”€ db/            # Story reader, knowledge writer
â”‚           â”‚   â”œâ”€â”€ extraction/    # LLM extractors (GPT-5-mini)
â”‚           â”‚   â”œâ”€â”€ resolution/    # Fuzzy entity matching
â”‚           â”‚   â””â”€â”€ pipelines/     # Orchestration pipeline
â”‚           â”œâ”€â”€ scripts/           # CLI tools
â”‚           â”œâ”€â”€ functions/         # Cloud Function deployment (future)
â”‚           â”œâ”€â”€ requirements.txt   # Module dependencies
â”‚           â”œâ”€â”€ schema.sql         # Database schema
â”‚           â””â”€â”€ README.md          # Module documentation
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”œâ”€â”€ requests/                      # Sample package requests
â””â”€â”€ README.md                      # This file
```

**Key Principles:**
- âœ… **Complete Independence**: Delete one module â†’ others still work
- âœ… **Isolated Dependencies**: Each module has its own `requirements.txt`
- âœ… **Separate Deployment**: Deploy functions independently
- âœ… **Minimal Shared Code**: Only generic utilities in `src/shared/`

**Import Patterns:**
```python
# Within a module (relative imports)
from ..data.fetch import fetch_data
from ...core.providers import Provider

# Shared utilities (absolute imports)
from src.shared.utils.logging import setup_logging
from src.shared.db import get_supabase_client

# âŒ Never import between function modules
# from src.functions.data_loading... in news_extraction
```

[**â†’ Architecture Details**](docs/architecture/function_isolation.md)

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.10+
- Supabase account
- Google Cloud account (for deployment)

### Shared Utilities

Available to all modules:

```python
from src.shared.utils.logging import setup_logging
from src.shared.db import get_supabase_client
from src.shared.utils.env import load_env
```

### Choose Your Module

Each module is independent:

- **Data Loading** â†’ [`src/functions/data_loading/README.md`](src/functions/data_loading/README.md)
- **News Extraction** â†’ [`src/functions/news_extraction/README.md`](src/functions/news_extraction/README.md)
- **Content Summarization** â†’ [`src/functions/content_summarization/README.md`](src/functions/content_summarization/README.md)
- **Story Embeddings** â†’ [`src/functions/story_embeddings/README.md`](src/functions/story_embeddings/README.md)
- **Story Grouping** â†’ [`src/functions/story_grouping/README.md`](src/functions/story_grouping/README.md)
- **Knowledge Extraction** â†’ [`src/functions/knowledge_extraction/README.md`](src/functions/knowledge_extraction/README.md)

---

## ğŸ“š Documentation

### Getting Started
1. **[README.md](README.md)** (this file) - Start here
2. **[Architecture & Design](docs/architecture/function_isolation.md)** - Understand the structure
3. **[Data Loading Module](src/functions/data_loading/README.md)** - NFL data ingestion & packages
4. **[News Extraction Module](src/functions/news_extraction/README.md)** - News URL extraction
5. **[Content Summarization Module](src/functions/content_summarization/README.md)** - AI-powered summarization
6. **[Story Embeddings Module](src/functions/story_embeddings/README.md)** - Vector embeddings for similarity search
7. **[Story Grouping Module](src/functions/story_grouping/README.md)** - Clustering similar stories
8. **[Knowledge Extraction Module](src/functions/knowledge_extraction/README.md)** - Topic and entity extraction

### Module Documentation
- **[Data Loading README](src/functions/data_loading/README.md)** â€“ Includes testing/deployment flow and the injuries loader reference
- **[News Extraction README](src/functions/news_extraction/README.md)** â€“ Covers CLI usage plus testing & cloud deployment steps
- **[Content Summarization README](src/functions/content_summarization/README.md)** â€“ Fact-first pipeline, backlog processor, knowledge/summary stages, and ops quick reference
- **[Story Embeddings README](src/functions/story_embeddings/README.md)** â€“ Embedding pipeline details and tuning flags
- **[Story Grouping README](src/functions/story_grouping/README.md)** â€“ Clustering algorithm, performance optimizations, schema
- **[Knowledge Extraction README](src/functions/knowledge_extraction/README.md)** â€“ Topic/entity extraction, batch processing, schema

### Technical References
- **[Package Contract](docs/package_contract.md)** - On-demand package request/response spec
- **[Cloud Function API](docs/cloud_function_api.md)** - HTTP API & deployment architecture
- **[Architecture & Design Principles](docs/architecture/function_isolation.md)** - Function isolation pattern

### Development
- **[AI Agent Instructions](AGENTS.md)** - Development guidelines for AI assistants

---

## ğŸ”§ Development Workflow

### Working on Data Loading

```bash
cd src/functions/data_loading

# Set up
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env  # Edit with your config

# Develop & test
python scripts/players_cli.py --dry-run
cd functions && ./run_local.sh

# Deploy
./deploy.sh
```

### Adding New Modules

Follow the same pattern as existing modules:

```
src/functions/your_module/
â”œâ”€â”€ core/              # Business logic
â”‚   â”œâ”€â”€ config/       # Configuration
â”‚   â”œâ”€â”€ data/         # Data processing
â”‚   â”œâ”€â”€ db/           # Database operations
â”‚   â””â”€â”€ ...           # Module-specific logic
â”œâ”€â”€ scripts/           # CLI tools
â”œâ”€â”€ functions/         # Cloud Function deployment
â”‚   â”œâ”€â”€ main.py       # Entry point
â”‚   â””â”€â”€ deploy.sh     # Deployment script
â”œâ”€â”€ requirements.txt   # Module dependencies
â”œâ”€â”€ .env.example      # Configuration template
â””â”€â”€ README.md         # Module documentation (include testing & deployment notes)
```

See [function_isolation.md](docs/architecture/function_isolation.md) for details.

---

## ğŸ” Troubleshooting

### Import Errors

**Problem**: `ModuleNotFoundError: No module named 'src'`

**Solution**: Make sure you're in the project root or set PYTHONPATH:
```bash
export PYTHONPATH="/path/to/T4L_data_loaders:$PYTHONPATH"
```

### Module Independence Test

Verify modules are truly independent:
```bash
# Test: data_loading works standalone
cd src/functions/data_loading
python scripts/players_cli.py --dry-run  # âœ… Should work

# Test: Delete one module, others still work
rm -rf src/functions/news_extraction
python scripts/players_cli.py --dry-run  # âœ… Still works!
```

---

## ğŸ†˜ Support

- **Architecture**: [docs/architecture/function_isolation.md](docs/architecture/function_isolation.md)
- **Data Loading**: [src/functions/data_loading/README.md](src/functions/data_loading/README.md)
- **News Extraction**: [src/functions/news_extraction/README.md](src/functions/news_extraction/README.md)
- **Content Summarization**: [src/functions/content_summarization/README.md](src/functions/content_summarization/README.md)
- **Story Embeddings**: [src/functions/story_embeddings/README.md](src/functions/story_embeddings/README.md)
- **Story Grouping**: [src/functions/story_grouping/README.md](src/functions/story_grouping/README.md)
- **Testing & Deployment**: Each module README now includes local testing and Cloud Function notes

---

**Built with function-based isolation for independence, scalability, and maintainability.** ğŸš€
